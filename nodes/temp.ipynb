{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_dataset = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_dataset = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_dataset, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([32, 3, 32, 32])\n",
      "Shape of y: torch.Size([32]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_stack1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=(3, 3), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d((2, 2))  \n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = self.conv_stack1(data)\n",
    "        return x\n",
    "    \n",
    "class ServerNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_stack2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d((2, 2))  \n",
    "        )\n",
    "\n",
    "        self.conv_stack3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d((2, 2))  \n",
    "        )\n",
    "\n",
    "        self.classification_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4*4*128, 10),\n",
    "            nn.Softmax(1)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = self.conv_stack2(data)\n",
    "        x = self.conv_stack3(x)\n",
    "        return self.classification_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ServerNN(\n",
      "  (conv_stack2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stack3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classification_stack): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): Linear(in_features=2048, out_features=10, bias=True)\n",
      "    (3): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "ClientNN(\n",
      "  (conv_stack1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "serverModel = ServerNN().to(device)\n",
    "clientModel = ClientNN().to(device)\n",
    "print(serverModel)\n",
    "print(clientModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "clientOptimizer = torch.optim.Adam(clientModel.parameters(), lr=3e-4)\n",
    "serverOptimizer = torch.optim.Adam(serverModel.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serverTrain(batch, clientOutputCPU, y, serverModel, loss_fn, serverOptimizer):\n",
    "    serverModel.train()\n",
    "    serverOptimizer.zero_grad()\n",
    "    clientOutput = clientOutputCPU.to(device)\n",
    "    pred = serverModel(clientOutput)\n",
    "    loss = loss_fn(pred, y)\n",
    "    loss.backward()\n",
    "    serverOptimizer.step()\n",
    "    loss_value = loss.item()\n",
    "    print(f\"Loss : {loss_value}, Batch : {batch}\")\n",
    "    return clientOutputCPU.grad.clone().detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clientTrain(dataloader, clientModel, serverModel, loss_fn, clientOptimizer, serverOptimizer):\n",
    "    clientModel.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        \n",
    "        clientOutput = clientModel(X)\n",
    "        clientOutput = clientOutput.clone().detach().requires_grad_(True)\n",
    "        grads = serverTrain(batch, clientOutput, y, serverModel, loss_fn, serverOptimizer)\n",
    "        clientOutput.backward(grads)\n",
    "        clientOptimizer.step()\n",
    "        clientOptimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started!\n",
      "Loss : 2.297450304031372, Batch : 0\n",
      "Loss : 2.247063159942627, Batch : 1\n",
      "Loss : 2.3187785148620605, Batch : 2\n",
      "Loss : 2.2961623668670654, Batch : 3\n",
      "Loss : 2.2806894779205322, Batch : 4\n",
      "Loss : 2.31801700592041, Batch : 5\n",
      "Loss : 2.2773256301879883, Batch : 6\n",
      "Loss : 2.2142996788024902, Batch : 7\n",
      "Loss : 2.261676073074341, Batch : 8\n",
      "Loss : 2.2241785526275635, Batch : 9\n",
      "Loss : 2.287748098373413, Batch : 10\n",
      "Loss : 2.2325687408447266, Batch : 11\n",
      "Loss : 2.2701210975646973, Batch : 12\n",
      "Loss : 2.246320962905884, Batch : 13\n",
      "Loss : 2.224458932876587, Batch : 14\n",
      "Loss : 2.2676734924316406, Batch : 15\n",
      "Loss : 2.1996219158172607, Batch : 16\n",
      "Loss : 2.197838306427002, Batch : 17\n",
      "Loss : 2.256319761276245, Batch : 18\n",
      "Loss : 2.256678581237793, Batch : 19\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m started!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mclientTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclientModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserverModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclientOptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserverOptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[46], line 8\u001b[0m, in \u001b[0;36mclientTrain\u001b[0;34m(dataloader, clientModel, serverModel, loss_fn, clientOptimizer, serverOptimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m clientOutput \u001b[38;5;241m=\u001b[39m clientModel(X)\n\u001b[1;32m      7\u001b[0m clientOutput \u001b[38;5;241m=\u001b[39m clientOutput\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mserverTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclientOutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserverModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserverOptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m clientOutput\u001b[38;5;241m.\u001b[39mbackward(grads)\n\u001b[1;32m     10\u001b[0m clientOptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[45], line 7\u001b[0m, in \u001b[0;36mserverTrain\u001b[0;34m(batch, clientOutputCPU, y, serverModel, loss_fn, serverOptimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m pred \u001b[38;5;241m=\u001b[39m serverModel(clientOutput)\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m serverOptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      9\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/mambaforge/envs/data-science/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/data-science/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch} started!\")\n",
    "    clientTrain(training_dataloader, clientModel, serverModel, loss_fn, clientOptimizer, serverOptimizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
